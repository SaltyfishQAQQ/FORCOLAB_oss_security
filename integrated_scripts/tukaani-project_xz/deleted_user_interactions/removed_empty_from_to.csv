from,to,positive,neutral,negative
Jia Tan,,"[{'message': 'Hello!\n\nThanks for the PR. This is a great start to improving the fuzz testing. I will start with a few overall comments here and then add some more specific comments directly on the commits themselves.\n\nFirst, we need to be sure that we are using the fuzz resources in the best way we can. Its easy to think of the OSS-Fuzz resources as unlimited, but each project can only be fuzzed so much. We should only include a fuzz target if it provides clear value and is testing an important part of liblzma that isn\'t being covered by a different fuzz target. Otherwise, less useful fuzz targets will take away compute time from the more useful ones. So, can you justify the reasoning behind each of the new fuzz targets? For instance, I am not sure that the raw encoder and decoder fuzz targets are useful since their important code paths are already covered by every other fuzz target. The raw coders don\'t have important header data, its just raw LZMA data. I am likely missing an important fuzz case, but in my mind I can think of three useful things to fuzz in our library:\n\n- Metadata encoding/decoding (magic bytes, file headers, block headers, lzma2 chunk headers, etc.)\n- Filter data encoding/decoding (LZMA1, BCJ, delta)\n- Check functions (CRC32, CRC64, SHA256)\n\nNext, the code itself has a lot of repeated boilerplate. Each of the fuzz targets has very little unique code. For instance, this could be reorganized into a shared header file that provides a function for encoding and a function for decoding. These functions can take the coder init function (lzma_alone_decoder(), lzma_auto_decoder(), etc.) as a function pointer arg and any needed flags or options.\n\nWe could also consider fuzzing the various BCJ filters (x86, PowerPC, ARM64, etc). These filters are designed to be applied to executable data, but will be run on non-executable data very often. So its possible that there are hidden data corruption bugs on an unexpected input sequence since they are mostly tested on executable data, making it a good candidate for fuzz testing. These filters cannot be used as raw coders at this time, so they will have to be combined in a filter chain with LZMA1/2. If we want to look for data corruption bugs, we should encode a chunk, then decode it and compare if the decoded version exactly matches the original data.\n\nFor your commit messages, we like to keep a consistent format. When we release, our Changelog is generated automatically from the contents of the commit messages. Also it helps us maintain our codebase better when the commit messages are descriptive and clear. For your commits, please have them start with the category of what they are changing. For these, I would prepend ""Tests:"" to the first line of each commit. The first line of each commit should be a brief description of the purpose of the commit. The following lines should explain what was changed and why. Make sure to wrap the lines of the commit message to at most 73 characters since different commit log viewers may or may not wrap long lines and it helps keep a consistent look in our Changelog.', 'score': 0.9773265372496098, 'timestamp': '2023-11-29T13:07:43Z', 'file_name': 'pr_73.csv'}, {'message': ""\nMakes perfect sense. I noted the BCJ filter fuzzing as option to consider. We don't necessarily need to implement it or implement it right away. Just an idea of something we could also be fuzzing if we agree the value is there.\n\n\nI think the simplest approach would be to use a common separate header file. Creating a dynamic template would take some extra build logic whereas an extra header file would only require updating the Makefile."", 'score': 0.6786818178370595, 'timestamp': '2023-11-29T16:52:47Z', 'file_name': 'pr_73.csv'}, {'message': ""\nWe like to keep our commits small and focused, so we will likely want more than one commit for this many changes. For now, don't worry about squashing your commits until the review is basically done. At the end we can figure out how many commits are appropriate for this and squash accordingly. So feel free to keep adding fix up commits as we go.\n\nI'll start reviewing your new changes."", 'score': 0.26617018366232514, 'timestamp': '2023-11-30T14:08:48Z', 'file_name': 'pr_73.csv'}, {'message': '\nIts safe to remove the `.lzma_raw` files and the `tests/files/README` changes.\n\nThanks for all the changes so far! I feel we are getting close to this being ready.', 'score': 0.9553973429137841, 'timestamp': '2023-12-01T13:31:19Z', 'file_name': 'pr_73.csv'}]","[{'message': ""\nThanks for looking into this!\n\nAfter some thought, it seems like a better use of resources to omit `fuzz_decode_stream_crc.c` and `fuzz_decode_lzip.c`. If we think the CRC code should be fuzzed we can add a fuzz target to directly test the various check functions. I'm not sure this will be needed since the input data to the check functions doesn't have much impact on the code path taken. On the Lzip side, this feature isn't used much and the header is very simple. We have tests that cover this in the test framework already so it doesn't feel worth the resources to fuzz it when we already have two other fuzz targets that hit the interesting code paths (alone and stream decoder).\n\nInstead, we should split `fuzz_encoder_stream` into two separate fuzz targets. The first could be called `fuzz_encode_stream` and the second `fuzz_encode_stream_light`. `fuzz_encode_stream` should use preset level 5 and `fuzz_encode_stream_light` should use preset level 1. \n\nAfter this, I think we are ready to squash the commits. As long as the commits are well organized it doesn't matter exactly how you choose to squash them. Here is one suggestion:\n\n1. Move `fuzz.c` to `fuzz_decode_stream.c`\n2. Separate logic from `fuzz_decode_stream.c` into `fuzz_common.h`\n3. Makefile changes\n4. Add `fuzz_decode_alone` fuzz target\n5. Add `fuzz_encode_stream` fuzz target\n6. Add `fuzz_encode_stream_light` fuzz target\n\nCommits 5 and 6 could be combined, up to you."", 'score': 0.14145337790250778, 'timestamp': '2023-12-04T14:25:55Z', 'file_name': 'pr_73.csv'}]","[{'message': ""\nI believe what was meant was that we have built up a very large corpus over the years on the `fuzz.c` fuzz target. Since that is renamed to `fuzz_decode_stream.c` in this PR, we would lose that large corpus if we do not take the proper steps to prevent that. We can either not rename this fuzz target or download a copy and restore it. I prefer the latter, and I have already downloaded a recent version of the corpus so it can be restored later.\n\n\nI don't see us incorporating CIFuzz since features get integrated into OSS-Fuzz soon after they are committed anyways. The real question is how OSS-Fuzz divides up time between fuzz targets. I have not seen any description of this on the OSS-Fuzz online documentation so we would likely have to look into their internals to truly answer that question.\n\n\nThe point here is that we don't want to over-emphasize the importance of code coverage. Fuzzing is computationally expensive so increasing the code coverage should only be done if we are increasing **meaningful** code coverage. I would much rather fuzz 1 complicated function that 10 simple ones.\n\nSo the goal shouldn't be to hit a certain percentage of code coverage. The goal should be to fuzz 100% of critical complicated code. And we don't expect you to know what all the critical complicated code in our project is, thats where we need to work together.\n\nWe do appreciate your efforts so far. I know it doesn't feel great to remove things, but in this case less is more.\n\nThe LZMA encoder certainly counts as critical complex code and that fuzz target adds a lot of value :)\n\n\nEach fuzz target needs to provide justifiable value outside of just extra code coverage. With the above points in mind, it feels safe to only consider the following fuzz targets:\n\n- fuzz_decode_alone. This test focuses on LZMA1 header/data fuzzing and EOPM handling.\n\n- fuzz_decode_lzip. This test focuses on LZIP header fuzzing. The LZIP header parsing is fairly simple and we have tests for it in the test framework, but maybe its still worth fuzzing.\n\n- fuzz_decode_stream_crc. This test focuses on portions not covered by fuzz_decode_stream. So mainly when the code leading to the check functions and the check functions themselves. The check functions are complicated and may deserve fuzzing, but the code leading to them may not really need fuzzing. So a more focused fuzz target that just calls the CRC and SHA256 functions directly could be more efficient since it avoids the LZMA decoding (which is covered by the other fuzzers).\n\n- fuzz_decode_stream. This test focuses on fuzzing .xz headers, block headers, index, etc. Additionally it fuzzes LZMA2 and LZMA1 decoding.\n\n- fuzz_encode_stream. This test focuses on encoding a .xz file including all of the things in fuzz_decode_stream, except on the encoder side.\n\nThere are a few areas where fuzzing could be expanded if we agree these are critical complex code paths:\n\n- BCJ Filters (already partially covered by fuzz_decode_stream)\n\n- Delta Filter (already partially covered by fuzz_decode_stream)\n\n- Different encoder settings (different match finders, dictionary sizes, LZMA properties, etc.). This could be accomplished by having an additional fuzz target for the encoder using preset 1. Instead of the default preset in `fuzz_encode_stream.c` we could use preset 5 since it should be a little faster (smaller `nice_len`) but have almost all the same settings. \n\nThe fuzzer machines do not have multiple cores, so unfortunately it doesn't make sense to fuzz the multithreaded stream encoder/decoder code. Otherwise that would be another candidate for critical complex code."", 'score': -0.24310237169265747, 'timestamp': '2023-12-02T13:27:20Z', 'file_name': 'pr_73.csv'}]"
,Jia Tan,"[{'message': ""\nThank you for the review! I've reverted the changes and added the `max_len=4096` to all fuzzer options. "", 'score': 0.9534805181901902, 'timestamp': '2023-12-01T13:58:48Z', 'file_name': 'pr_73.csv'}]",[],"[{'message': 'A follow up on the redundant fuzzers: I ran the setup without them, and the coverage difference is indeed negligible. I am removing them from the pull request', 'score': -0.9570345066022128, 'timestamp': '2023-12-01T12:35:26Z', 'file_name': 'pr_73.csv'}, {'message': 'Also, I am now questioning whether the addition of `.lzma_raw` files is needed, since the corresponding fuzzers were removed from the pull request', 'score': -0.6954786092974246, 'timestamp': '2023-12-01T13:06:18Z', 'file_name': 'pr_73.csv'}]"
Lasse Collin,,"[{'message': ""Thanks to both of you for your work so far!\n\nThere are a few things I would like to understand better. I have only skimmed OSS-Fuzz's docs so I might be asking silly questions, sorry.\n\n1. Seems that [renaming a fuzz target](https://google.github.io/oss-fuzz/faq/#what-happens-when-i-rename-a-fuzz-target-) requires renaming the accumulated corpora too.\n\n2. Does adding more fuzzers mean that the project-specific fuzzing resources (processor time) will be divided between the fuzzers? With a quick look I didn't find any advice about resource usage in OSS-Fuzz docs and it's not discussed much in this thread either.\n\n3. The value of code coverage in fuzzing is unclear. *If* extending coverage by a few simple lines of code could slow down fuzzing of more important parts of the code, does it make sense to extend fuzzing coverage in that case? I'm thinking of cases where an old-school code review shouldn't take a lot of time (code snippets that are about 200 lines each and do nothing unusually complicated). Or perhaps these should be fuzzed at first but disabled after some time if they find nothing?\n\nExamples of remaining significant overlap in the new fuzzing targets:\n\n* fuzz_encode_alone.c would test end of payload marker (EOPM) encoding in LZMA but otherwise it doesn't test much that won't be tested by fuzz_encode_stream.c. They both use the LZMA encoder in the end. So it seems that fuzz_encode_alone.c isn't useful and could _maybe_ even be harmful due to resource usage unless the fuzzers are smart enough to spot when code paths become identical.\n\n* fuzz_decode_alone.c splits into three different decoders depending on the input. Yet the three decoders are fuzzed separately too (stream, alone, lzip). So the only extra fuzzed thing is the small auto_decoder.c.\n\nI don't know enough about the fuzzing methods to know what actually makes sense. I would like to be assured that adding all these fuzzers adds real value.\n\nThanks!"", 'score': 0.748419402167201, 'timestamp': '2023-12-01T17:19:14Z', 'file_name': 'pr_73.csv'}]",[],[]
Sam James,,[],"[{'message': 'I think we should keep this open so the build system can work around it.', 'score': 0.0407179300673306, 'timestamp': '2023-11-15T04:00:20Z', 'file_name': 'issue_70.csv'}]",[]
,Lasse Collin,[],"[{'message': '\nan ifunc WILL compile and link successfully in a dynamically built program, but musl does not implement ifunc (GNU glibc only extension)', 'score': -0.0008266419172286987, 'timestamp': '2023-11-16T19:01:15Z', 'file_name': 'issue_70.csv'}, {'message': 'we could extract the triple on gcc/clang via `-dumpmachine`\n\n```\n$ clang -dumpmachine\nx86_64-alpine-linux-musl\n```', 'score': 0.020837008021771908, 'timestamp': '2023-11-17T08:28:35Z', 'file_name': 'issue_70.csv'}]","[{'message': 'a crude hack to detect musl is to detect /lib/ld-musl-*', 'score': -0.375386327970773, 'timestamp': '2023-11-16T19:02:25Z', 'file_name': 'issue_70.csv'}]"
Lasse Collin,,[],[],"[{'message': ""\nYes, I relealized this as I wrote in my next message. Since GCC upstream knows that musl doesn't support ifunc, I wonder if Clang/LLVM should know it too and then warn or error if the ifunc attribute is used. That is, I wonder if this could be a Clang/LLVM bug.\n\n\nIn Autoconf, checking if `$host_os` equals `linux-musl` probably is the correct method. I don't know right now how to detect it in CMake.\n\nAccording to musl's FAQ, there intentionally is no easy `#ifdef` to detect musl in C code.\n\nHacks like checking file paths wouldn't work when cross-compiling.\n\nOn the second thought, uClibc might not support ifunc either. It could be better to detect glibc, so `linux-gnu` in case of Autoconf (maybe FreeBSD too). But once again I don't know right now how to detect the libc in CMake."", 'score': -0.23173872381448746, 'timestamp': '2023-11-16T19:55:30Z', 'file_name': 'issue_70.csv'}]"
Jia Tan,,[],"[{'message': ""\nThe default build options need to create a working build on all of our supported platforms. Right now people can just disable ifunc for a working musl build as you discovered with `-DALLOW_ATTR_IFUNC=OFF`. That is only a temporary workaround since we want to make our build systems as easy to use for people as possible.\n\nI have been working a [branch](https://github.com/tukaani-project/xz/tree/ifunc_detect_fix) to address this. The idea is to change the ifunc option for our CMake and Autotools build from ON/OFF or enable/disable to auto/ON/OFF. 'auto' will try to enforce using ifunc with glibc or BSD platforms only. ON will always try to use ifunc and OFF will obviously disable ifunc completely. Both auto and ON will still test the compiler if it supports `__attribute__((__ifunc__()))`.\n\nIf you can test the new branch on Alpine that would be very helpful. I tested with `musl-gcc` wrapper and things seemed to work. We haven't decided 100% if this is the approach we want to take but it seems promising so far.\n\nThanks for all of your help so far!"", 'score': 0.03344202600419521, 'timestamp': '2023-11-27T13:03:57Z', 'file_name': 'issue_70.csv'}, {'message': ""Our CMake support is considered unstable and is undergoing a lot of improvements. Many of these improvements are already on master but have not made it into a stable release. If you only need `liblzma`, then using a release from the 5.4 branch will work. We will have a new `5.4.5` release later today and that will include a few small CMake changes. We recently ported the command line tools `xz` and `xzdec` to MSVC but that will not be part of any of the 5.4 releases\n\nWe are planning to release 5.6.0 this December which may change the default library to being a shared library. We may consider our CMake support stable at that point. So, to be safe you should explicitly set the `BUILD_SHARED_LIBS` option if you do build `liblzma` through CMake since this option's default value specifically might not be stable.\n\nIf you can use our Autotools build system on Windows through something like Cygwin or MSYS2, that is recommended over CMake at the moment. If not, our CMake build will likely still work for you, but be careful of minor things changing in the future. We generally don't break things with our CMake build and are usually just adding more features. I hope this answers your question!"", 'score': -0.07522442378103733, 'timestamp': '2023-10-31T16:05:35Z', 'file_name': 'issue_68.csv'}]","[{'message': ""\nI don't think this will work for us since a tool like `musl-gcc` (a GCC wrapper for using musl libc) still outputs `x86_64-linux-gnu` with `-dumpmachine`. So this would fix things for Alpine, but our builds would still be broken for anyone compiling for musl libc using a wrapper like this.\n"", 'score': -0.878083897056058, 'timestamp': '2023-11-23T16:05:13Z', 'file_name': 'issue_70.csv'}]"
,Jia Tan,"[{'message': '\nTested on alpine, it works ^^', 'score': 0.7953602554043755, 'timestamp': '2023-11-29T09:42:54Z', 'file_name': 'issue_70.csv'}, {'message': '\nMatthew Good', 'score': 0.7599202319979668, 'timestamp': '2023-11-30T12:18:19Z', 'file_name': 'issue_70.csv'}]","[{'message': '\nHmmm', 'score': 0.08717402815818787, 'timestamp': '2023-11-27T03:48:00Z', 'file_name': 'issue_70.csv'}, {'message': 'Maybe we could just add a define for musl\n\nmake -D MUSL=1\n\nand trust the builder to pass this define when building on a musl distro', 'score': 0.008924373425543308, 'timestamp': '2023-11-27T03:49:11Z', 'file_name': 'issue_70.csv'}, {'message': 'Alright\n\nOn Mon, 27 Nov 2023, 11:04 pm Jia Tan, ***@***.***> wrote:\n', 'score': 0.025654828175902367, 'timestamp': '2023-11-27T13:08:16Z', 'file_name': 'issue_70.csv'}]",[]
,,[],[],"[{'message': 'same here; can not compile xz-5.6.0 on opensuse leap 15.5, ""xzdec.c:329:29: error: ‘SYS_landlock_create_ruleset’ undeclared"",  ""xzdec.c:349:15: error: ‘SYS_landlock_restrict_self’ undeclared""\n\nseems, the unconditional use of SYS_landlock_... in xz-5.6.0 sources has somehow to be guarded if not-so-recent glibc is installed on the host', 'score': -0.8788819476030767, 'timestamp': '2024-02-25T20:59:02Z', 'file_name': 'issue_88.csv'}]"
,Jia Tan,"[{'message': 'yes,  ""./autogen.sh;./configure;make;make check"" successful :-)\n\nthanks for the quick resolution', 'score': 0.974935830803588, 'timestamp': '2024-02-26T17:17:09Z', 'file_name': 'issue_88.csv'}]","[{'message': 'any road map / time line, when a release containing the fix could be available?', 'score': -0.007229913957417011, 'timestamp': '2024-02-26T17:20:58Z', 'file_name': 'issue_88.csv'}, {'message': 'ok, it is not urgent for me.\nthanks for your elaboration on sandbox and the SYS_landlock_... calls.', 'score': -0.0025714635848999023, 'timestamp': '2024-02-27T12:49:17Z', 'file_name': 'issue_88.csv'}]",[]
Jia Tan,,"[{'message': 'We left this open so others could see this was a known bug. Closing now since the fix is included in 5.6.1. Thank you to everyone for reporting this and verifying it works now :)', 'score': 0.8724028433207422, 'timestamp': '2024-03-11T14:37:01Z', 'file_name': 'issue_88.csv'}]",[],"[{'message': ""\nWe don't have an exact date yet for the next release (5.6.1) since we want to wait for more possible bug reports to come in. It should only be a few weeks though :)\n\nFor this problem, if you need to use the 5.6.0 release you can just add `--disable-sandbox` to the `configure` command. You will not be missing out on the sandbox feature unnecessarily because unfortunately your system cannot support this feature until your system call definitions include `SYS_landlock_create_ruleset` and `SYS_landlock_restrict_self`."", 'score': -0.5616111820563674, 'timestamp': '2024-02-27T12:24:35Z', 'file_name': 'issue_88.csv'}]"
Sam James,,[],"[{'message': ""Please see https://github.com/tukaani-project/xz/commit/6daa4d0ea46a8441f21f609149f3633158bf4704:\n\nI believe (although see if a maintainer confirms) that the threaded compressor is deterministic - it doesn't depend on the thread count and so on, so even with 1 thread, the threaded compressor output is the same. I believe the only difference is that it's chunked / includes sizes so it can be decompressed in parallel.\n\nIt's just that it's different compared to the non-threaded compressor.\n\nBut the non-threaded compressor could've changed output at some point anyway, it just didn't.\n\n`xz(1)` also says:"", 'score': 0.053294360637664795, 'timestamp': '2024-02-24T17:07:38Z', 'file_name': 'issue_85.csv'}]",[]
,Jia Tan,"[{'message': 'Thanks for clearing things up!', 'score': 0.9499307367950678, 'timestamp': '2024-02-25T14:19:57Z', 'file_name': 'issue_85.csv'}]",[],[]
Lasse Collin,,"[{'message': 'Seems to work fine at the moment. The hosting provider had reported that a denial of service attack happened 2-3 days ago.\n\nThe 5.4.2 release is available on GitHub and also on [Sourceforge](https://sourceforge.net/projects/lzmautils/files/). Future release will use github.com as the primary download URL for unrelated reasons.', 'score': 0.2232960145920515, 'timestamp': '2024-01-14T15:44:13Z', 'file_name': 'issue_78.csv'}]",[],[]
,Lasse Collin,[],"[{'message': ""Hello,\n\nHas there been any progress on a prototype for that feature? If not, I'd like to take a stab at it in Java."", 'score': 0.1401216210797429, 'timestamp': '2024-09-25T12:26:10Z', 'file_name': 'issue_50.csv'}]",[]
Lasse Collin,,[],[],"[{'message': 'No progress at least from my side. Feel free to experiment.', 'score': -0.7684330334886909, 'timestamp': '2024-09-25T12:35:25Z', 'file_name': 'issue_50.csv'}]"
,Azrael,[],[],"[{'message': 'There is a live FAQ on this issue:\n\nhttps://gist.github.com/thesamesam/223949d5a074ebc3dce9ee78baad9e27\n\nAnd to quote from the current version of the `People` part:\n\n````\nPeople\n\nWe do not want to speculate on the people behind this project in this document.\nThis is not a productive use of our time, and law enforcement will be able to handle identifying those responsible.\nThey are likely patching their systems too.\n\nxz-utils has two maintainers:\n\n    Lasse Collin (Larzhu) who has maintained xz since the beginning (~2009), and before that, lzma-utils.\n    Jia Tan (JiaT75) who started contributing to xz in the last 2-2.5 years and gained commit access,\n    and then release manager rights, about 1.5 years ago.\n\nLasse regularly has internet breaks and is on one at the moment, started before this all kicked off.\nWe believe CISA may be trying to get in contact with him.\n````', 'score': -0.6209486979059875, 'timestamp': '2024-03-29T21:24:19Z', 'file_name': 'issue_92.csv'}]"
,,[],[],"[{'message': ""why do we need 700 different compression libraries linked to everything?  There's nothing xz does that zlib doesn't for the usecase here.  Saving a handful of bytes on already-tiny files isn't worth requiring everything to use all of: libbz2, liblz4, liblzma, libxz and libzstd.\n\nE: that's a whole lot of anonymous cowards hiding behind shitty reaction emojis because they don't understand the issue."", 'score': -0.9221290845889598, 'timestamp': '2024-03-29T21:25:55Z', 'file_name': 'issue_92.csv'}]"
,Henrik Gaßmann,[],[],"[{'message': 'Whats with chinks always trying to get into my ssh? first it was just the bruteforce loggin attempts, now they want to get in from the inside.', 'score': -0.9216774390079081, 'timestamp': '2024-03-29T22:17:59Z', 'file_name': 'issue_92.csv'}]"
,Tejeev,[],"[{'message': '\nI have no clue what you are trying to say, but on the off chance that you are not in the world of software engineering, here is a screenshot of me making a git commit with UTC+8 (note on the top right, my local time is UTC+11)\n\n![image](https://github.com/tukaani-project/xz/assets/2950544/f9be5494-f71f-42bc-aff7-911ae36abeea)', 'score': -0.008720844984054565, 'timestamp': '2024-03-29T23:11:44Z', 'file_name': 'issue_92.csv'}]",[]
Hakkin Lain,,[],"[{'message': '\nIt\'s interesting to note that the ""Jigar Kumar"" in this thread that is pressuring Lasse to find a replacement maintainer has the same e-mail format (`<firstname><lastname><number>`) as the ""Hans Jansen"" e-mail that was part of the backdoored commits. The PGP key for the Protonmail account (`0xA97B6FC34F5DB756`) was created on `2022-04-26`, and the first message by ""Jigar Kumar"" on the xz-devel mailing list was on `2022-04-27`, one day later.\n\nIt\'s seeming increasingly likely that every step of this process was carefully orchestrated by multiple sockpuppet accounts controlled by the same actor.', 'score': 0.06921318732202053, 'timestamp': '2024-03-29T23:16:35Z', 'file_name': 'issue_92.csv'}]",[]
,Alan Coopersmith,[],[],"[{'message': '\nLocked by who though?', 'score': -0.263714044354856, 'timestamp': '2024-03-29T23:22:00Z', 'file_name': 'issue_92.csv'}]"
,P-EB,[],"[{'message': 'nan', 'score': 0.028908006846904755, 'timestamp': '2024-03-29T23:48:06Z', 'file_name': 'issue_92.csv'}]","[{'message': '\nhttps://www.openwall.com/lists/oss-security/2024/03/29/4  Like this one?\n\nAm I misunderstanding what ""oss-security"" is?', 'score': -0.36648282408714294, 'timestamp': '2024-03-29T23:44:04Z', 'file_name': 'issue_92.csv'}]"
P-EB,,[],"[{'message': '\nNo. From Lasse.', 'score': 0.022542782127857208, 'timestamp': '2024-03-29T23:45:01Z', 'file_name': 'issue_92.csv'}]",[]
mirabilos,,[],[],"[{'message': 'Debian is currently looking into downgrading it even further, before the first contribution from the known bad actor, which may be an older 5.2 release (later ones were also cut by them), then reapplying only the security fixes that came later on top manually, for now.', 'score': -0.38079884089529514, 'timestamp': '2024-03-29T23:51:02Z', 'file_name': 'issue_92.csv'}]"
Azrael,,[],"[{'message': '\nSee the linked PR.', 'score': 0.005253341980278492, 'timestamp': '2024-03-29T21:46:21Z', 'file_name': 'issue_96.csv'}]",[]
,Dirk Mueller,[],[],"[{'message': ""\nWell at least on my system i have glibc installed. Arch Linux was also affected (at least they commited a fix), and they don't have a deb or rpm package. "", 'score': -0.27879811078310013, 'timestamp': '2024-03-29T21:50:35Z', 'file_name': 'issue_96.csv'}]"
Ben Greiner,,[],[],"[{'message': '\nThe kids over there just don\'t know what they are talking about. Also their ""fix"" is to use the github repo instead of the tarball. So it still contains lots of puzzle pieces of the backdoor, just not the build trigger which would supposedly not activate in pkgbuild anyway.', 'score': -0.9246290698647499, 'timestamp': '2024-03-29T22:01:19Z', 'file_name': 'issue_96.csv'}]"
Sam James,,[],"[{'message': 'Please see the discussion in https://github.com/tukaani-project/xz/pull/52.', 'score': 0.021761708427220583, 'timestamp': '2023-06-29T16:53:09Z', 'file_name': 'issue_54.csv'}]",[]
,Sam James,"[{'message': 'Great, thank you very much!\n\nDoes the test suite consist in invoking the following executables, or do I need to invoke them in some special way, or are there perhaps other scripts to run? (these executables are what I get in the tests directory when building to 32bit Windows with mingw-w64)\n\n```\ntests/create_compress_files.exe\ttests/test_check.exe\t\ttests/test_hardware.exe\t\ttests/test_lzip_decoder.exe\ttests/test_vli.exe\ntests/test_bcj_exact_size.exe\ttests/test_filter_flags.exe\ttests/test_index.exe\t\ttests/test_memlimit.exe\ntests/test_block_header.exe\ttests/test_filter_str.exe\ttests/test_index_hash.exe\ttests/test_stream_flags.exe\n```', 'score': 0.9519577431492507, 'timestamp': '2023-06-29T17:00:18Z', 'file_name': 'issue_54.csv'}, {'message': 'You are free to close this issue, unless you feel that something could be added. Thank you very much!!', 'score': 0.42011679522693157, 'timestamp': '2023-06-30T09:15:03Z', 'file_name': 'issue_54.csv'}]","[{'message': ""Everything clear, I think. I have created this batch file which, AFAIK, runs all the tests that can be run from cross-compilation.\n\nThere's an extra step, though, before running this batch file, and it's that you must copy the complete `files` folder (located under the `tests` folder in the source code) into the built `tests` folder, for the script to run:\n\n```\ntest_bcj_exact_size.exe || exit /b\ntest_block_header.exe || exit /b\ntest_check.exe || exit /b\ntest_filter_flags.exe || exit /b\ntest_filter_str.exe || exit /b\ntest_hardware.exe || exit /b\ntest_index.exe || exit /b\ntest_index_hash.exe || exit /b\ntest_lzip_decoder.exe || exit /b\ntest_memlimit.exe || exit /b\ntest_stream_flags.exe || exit /b\ntest_vli.exe || exit /b\n```"", 'score': 0.07172243064269423, 'timestamp': '2023-06-30T09:13:35Z', 'file_name': 'issue_54.csv'}]",[]
Jia Tan,,"[{'message': ""Hello!\n\nThank you for the feature request. Currently, we do not have any official benchmark framework for any of the XZ projects. When we develop new features that require benchmarking data, we tend to collect the files with characteristics that best fit that feature (data type, size, entropy, etc.). Often times community members will also help us benchmark since they may have access to machines, data, or ideas that the maintainers do not.\n\nAs such, we do not have any plans for a more official, robust, and structured benchmark framework at this time. We unfortunately have a few high priority tasks to attend to first. Eventually, this could be a nice thing to have when we revisit encoder/decoder optimizations to make it easier for the community to help us test various ideas. We would likely maintain a separate repository for this so it could be useful for other .xz implementations.\n\nIf you have ideas on good ways to do this or bad things we should avoid, we are always open to suggestions :) . We probably wouldn't want to actually host the benchmark data ourselves due to storage requirements and potential file distribution copyright complexities, but a bring-your-own-data framework could be useful for people. Such a thing may already exist, so we would need to start by surveying what solutions other projects use for something like this. "", 'score': 0.46102565433830023, 'timestamp': '2024-02-28T13:33:24Z', 'file_name': 'issue_83.csv'}]",[],[]
,Jia Tan,"[{'message': 'Hi,\nzstd has a nice integrated benchmark feature:\n```\n$ zstd -b\n 3#Synthetic 50%     :  10000000 ->   3230847 (x3.095),  346.2 MB/s, 2616.6 MB/s\n```\nIt is useful to have an easily reproducible test.\nIn xz it could help to test which variant among\n* Basic C version\n* Branchless C\n* x86-64 inline assembly\n\nis the fastest on a given system.\n\nIt would be even better if all 3 variants could be compiled into the same binary and chosen at runtime.', 'score': 0.8981265474576503, 'timestamp': '2024-03-29T11:22:45Z', 'file_name': 'issue_83.csv'}]",[],[]
Caleb Maclennan,,[],"[{'message': '\nWould those ""high priority"" tasks by any chance include [backdooring Debian & Redhat based distros](https://www.openwall.com/lists/oss-security/2024/03/29/4)?', 'score': 0.010562228038907051, 'timestamp': '2024-03-29T18:16:24Z', 'file_name': 'issue_83.csv'}]",[]
,Caleb Maclennan,"[{'message': 'The only true benchmark for any compression software is the hutter prize: http://prize.hutter1.net/\nXZ is ranked place 75 in that regard, which is not bad: http://mattmahoney.net/dc/text.html', 'score': 0.9150293359998614, 'timestamp': '2024-04-17T22:32:00Z', 'file_name': 'issue_83.csv'}]",[],[]
,Michael Catanzaro,[],[],"[{'message': '\nThere is no commit in this repo that is malicious, but the tarballs that are being distributed in this repo are malicious. See the Red Hat security advisory at https://www.redhat.com/en/blog/urgent-security-alert-fedora-41-and-rawhide-users', 'score': -0.9508035653270781, 'timestamp': '2024-03-29T19:56:47Z', 'file_name': 'issue_94.csv'}]"
Jia Tan,,[],"[{'message': 'Hi! Thank you for the code suggestion. In order for us to accept a change like this, we need more information about the problem that is solves. What is the need to compile the tests programs locally without running them? Is it a cross-compile situation where you want to copy over the test binaries after everything else is built?\n\nIf this is the case, then a better solution is to override the TESTS variable in a make check command to be empty on your build machine:\n\n`make check TESTS=`\n\nThe TESTS variable, from the Automake docs: \n\n""If the special variable TESTS is defined, its value is taken to be a list of programs or scripts to run in order to do the testing.""\n\nSo, this is the list of tests to execute. If you leave it empty, it will still build all of the tests and then not execute any. Would this solve the issue?', 'score': 0.10053827334195375, 'timestamp': '2023-06-05T15:03:54Z', 'file_name': 'pr_52.csv'}]",[]
,Jia Tan,"[{'message': '\nAs you mentioned, it is a cross-compile situation where I want to copy over the test binaries after everything else is built. \nTo be precise, I want to add ""ptest"" support for xz in ""openembedded core"", so there is the situations where only local compilation is done without running tests.\n\nI have tried the method you suggested and it can also solve my problem very well, so there is no need to modify the code in xz.\nFinally, I would like to thank you for your patient comment. \nThank you!', 'score': 0.9002405425999314, 'timestamp': '2023-06-07T08:52:37Z', 'file_name': 'pr_52.csv'}]","[{'message': 'My problem has been resolved, so I will close this issue.\nThank you for your reply.', 'score': -0.022082332521677017, 'timestamp': '2023-06-07T08:55:07Z', 'file_name': 'pr_52.csv'}]",[]
Sam James,,[],[],"[{'message': ""Not sure that's right. At the very least, the fork count went down to 0 as did star count on the main repo. Plus the repo that his now shows as a fork of is also disabled.\n\nWe also can't reopen [any other PRs](https://github.com/tukaani-project/xz/pull/93#event-12447440884), so..."", 'score': -0.9527452148031443, 'timestamp': '2024-04-14T12:10:46Z', 'file_name': 'pr_86.csv'}]"
,Xi Ruoyao,[],"[{'message': ""I think what happened then is: the forks got suspended, but there were a few mirrors of the xz repo, which didn't get suspended."", 'score': -0.030011766590178013, 'timestamp': '2024-04-14T19:05:21Z', 'file_name': 'pr_86.csv'}]",[]
Xi Ruoyao,,[],"[{'message': ""In the meantime I'm having an eye on https://gcc.gnu.org/pipermail/gcc-patches/2024-May/652612.html.  If it's landed it'd be better to use the generic built-in instead of target-specific intrinsic."", 'score': 0.03758898191154003, 'timestamp': '2024-05-26T11:15:10Z', 'file_name': 'pr_86.csv'}]",[]
Jia Tan,,"[{'message': 'Omitting assembly from x86-32 is certainly much simpler than trying to adapt for it. Thanks for the PR! This is merged in master as e9053c907250c70d98b319d95fa54cb94fc76869. ', 'score': 0.6583510804921389, 'timestamp': '2024-02-17T14:31:22Z', 'file_name': 'pr_80.csv'}]",[],[]
Jia Tan,,"[{'message': 'Hi! Thanks again for the very detailed PR. I looked more into wasm signal support since at first I thought it was some sort of bug that the signal emulation did not define `sigset_t` or `sigprocmask()`. This seems intentional however so your PR is certainly needed for a successful port to web assembly.\n\nWhat you have so far seems like it is enough for liblzma to build, but we also should support an xz port. This should be easy to add just by following the example of VMS in src/xz/signal.*. Since the only functions in xz that use `mythread_sigmask()` it should be enough to define signals_block() and signals_unblock() as no-ops in signal.h (and remove implementation from signal.c).\n\nLet me know if you have questions or if something else is preventing us from building xz with wasi-sdk', 'score': 0.8370748800225556, 'timestamp': '2023-07-27T13:03:32Z', 'file_name': 'pr_57.csv'}]","[{'message': 'Thanks for the updated error message. Can I ask more about your build environment? The `<signal.h>` header file should provide definitions for `sigset_t` and `sigprocmask()` in a POSIX compliant system and the preprocessor should filter out Windows builds that do not set the `__CYGWIN__` macro.\n\nThe reason I want to avoid removing `#include ""mythread.h""` from `common.h` is\n1. Avoid breaking something unexpectedly\n2. It allows referencing `MYTHREAD_ENABLED` just by including `common.h`. Our `common.h` header files includes `config.h` (when building with autotools) and that contains all of the configurations. So it makes the liblzma files simpler since they only need to include `common.h` to get all configurations.\n\nUsually only including the header files you actually need is a good idea. In this case, there are few other files that would need to include `mythread.h` for it to work. But I would like to avoid this if possible.', 'score': -0.04872218705713749, 'timestamp': '2023-07-26T14:47:44Z', 'file_name': 'pr_56.csv'}]","[{'message': 'On second thought, will be more complicated that I initially thought since `signals_init()` needs to be disabled too. I will merge what you have once I make a fix for the xz side. Thanks for you contributions!', 'score': -0.23721229285001755, 'timestamp': '2023-07-27T13:18:08Z', 'file_name': 'pr_57.csv'}, {'message': 'Hi! Thanks for the PR. Unfortunatly, I do not think this PR solves a problem. I am guessing the issue is with your build setup instead. If you look at `mythread.h`, the functions referenced in your error message are in the `#elif defined(MYTHREAD_POSIX)` block and should be removed by the preprocessor.\n\nIf you are using our `CMakeLists.txt`, then setting `ENABLE_THREADS=OFF` will ensure `MYTHREAD_POSIX` is never added to the compile definitions. Its possible a `make clean` or removing the `CMakeCache.txt` could solve your problem.\n\nCompiling liblzma with WebAssembly sounds like a great project though!', 'score': -0.7127985511906445, 'timestamp': '2023-07-26T14:15:35Z', 'file_name': 'pr_56.csv'}]"
,Jia Tan,"[{'message': 'Thank you for your kind review!\n\nI am honored to contribute to your project!', 'score': 0.99075969948899, 'timestamp': '2023-07-27T13:40:29Z', 'file_name': 'pr_57.csv'}, {'message': 'Thank you! I updated my profile name. I would appreciate it if you could add this name to the THANKS file!', 'score': 0.98224695737008, 'timestamp': '2023-08-01T15:56:21Z', 'file_name': 'pr_57.csv'}]","[{'message': 'Thanks for review!\n\nSorry. The error message I pasted was the wrong one\n\nThis is correct\n```\n  running: ""clang"" ""-O0"" ""-ffunction-sections"" ""-fdata-sections"" ""-fPIC"" ""-g"" ""-fno-omit-frame-pointer"" ""--target=wasm32-wasi"" ""--sysroot"" ""/wasi-sdk-20.0/share/wasi-sysroot"" ""-D_WASI_EMULATED_SIGNAL"" ""-I"" ""xz-5.2/src/liblzma/api"" ""-I"" ""xz-5.2/src/liblzma/lzma"" ""-I"" ""xz-5.2/src/liblzma/lz"" ""-I"" ""xz-5.2/src/liblzma/check"" ""-I"" ""xz-5.2/src/liblzma/simple"" ""-I"" ""xz-5.2/src/liblzma/delta"" ""-I"" ""xz-5.2/src/liblzma/common"" ""-I"" ""xz-5.2/src/liblzma/rangecoder"" ""-I"" ""xz-5.2/src/common"" ""-I"" ""/xz2-rs/lzma-sys"" ""-std=c99"" ""-pthread"" ""-DHAVE_CONFIG_H=1"" ""-o"" ""/xz2-rs/target/wasm32-wasi/debug/build/lzma-sys-7bbeecf3b4119da3/out/xz-5.2/src/liblzma/check/check.o"" ""-c"" ""xz-5.2/src/liblzma/check/check.c""\n  cargo:warning=In file included from xz-5.2/src/liblzma/check/check.c:13:\n  cargo:warning=In file included from xz-5.2/src/liblzma/check/check.h:16:\n  cargo:warning=In file included from xz-5.2/src/liblzma/common/common.h:17:\n  cargo:warning=xz-5.2/src/common/mythread.h:87:33: error: unknown type name \'sigset_t\'\n  cargo:warning=mythread_sigmask(int how, const sigset_t *restrict set,\n  cargo:warning=                                ^\n  cargo:warning=xz-5.2/src/common/mythread.h:88:3: error: unknown type name \'sigset_t\'\n  cargo:warning=                sigset_t *restrict oset)\n  cargo:warning=                ^\n  cargo:warning=xz-5.2/src/common/mythread.h:90:12: warning: call to undeclared function \'sigprocmask\'; ISO C99 and later do not support implicit function declarations [-Wimplicit-function-declaration]\n  cargo:warning=        int ret = sigprocmask(how, set, oset);\n  cargo:warning=                  ^\n  cargo:warning=1 warning and 2 errors generated.\n  exit status: 1\n```', 'score': -0.007666438817977905, 'timestamp': '2023-07-26T14:33:21Z', 'file_name': 'pr_56.csv'}, {'message': ""I am using the latest WASI-SDK.\nWASI is trying to provide a project that provides a POSIX compatible API as WASIX but it seems it's not perfect yet.\n\nThere is no deep meaning in using it via Rust, so if you can use Docker, I think you can reproduce the equivalent environment with the following `Dockerfile`\n\n```dockerfile\nFROM ghcr.io/webassembly/wasi-sdk:latest\n\nRUN apt update && apt install -y git\n\nRUN git clone https://github.com/tukaani-project/xz.git\n\nRUN ./xz/build-aux/ci_build.sh -b cmake -d threads,shared -p all\n\n```\n\n```sh\n$ docker build -t xz .\n```\n\nWASI-SDK can download from https://github.com/WebAssembly/wasi-sdk/releases/tag/wasi-sdk-20"", 'score': -0.1346343792974949, 'timestamp': '2023-07-26T14:56:57Z', 'file_name': 'pr_56.csv'}, {'message': 'It\'s a little redundant description, but how about adding the following changes\n\n`common.h`\n```diff\n-#include ""mythread.h""\n+// If any type of threading is enabled, #include ""mythread.h"".\n+#if defined(MYTHREAD_POSIX) || defined(MYTHREAD_WIN95) \\\n+\t\t|| defined(MYTHREAD_VISTA)\n+#\tinclude ""mythread.h""\n+#endif\n```\n\nI think this will solve 2.', 'score': 0.04207393852993846, 'timestamp': '2023-07-26T15:36:29Z', 'file_name': 'pr_56.csv'}]",[]
Jia Tan,,"[{'message': 'Hi! Thanks for the bug report and PR.\n\nAll of the targets that need to be compiled require C99, so it would be better to just set the CMAKE_C_STANDARD variable at the top of CMakeLists.txt like this:\n\n```\nset(CMAKE_C_STANDARD 99)\n```', 'score': 0.23033889941871166, 'timestamp': '2023-02-27T12:33:26Z', 'file_name': 'pr_42.csv'}]",[],"[{'message': 'The liblzma API headers should be compatible with C89, but the internal headers used by the source code are not. ', 'score': -0.7217811197042465, 'timestamp': '2023-02-27T13:09:18Z', 'file_name': 'pr_42.csv'}]"
,Jia Tan,[],"[{'message': 'Do the headers also require C99 or only the source code?', 'score': -0.02564205415546894, 'timestamp': '2023-02-27T12:40:38Z', 'file_name': 'pr_42.csv'}]",[]
Deleted user,,"[{'message': 'LGTM! :P', 'score': 0.558903347235173, 'timestamp': '2024-03-29T21:44:04Z', 'file_name': 'pr_95.csv'}]",[],[]
,Sam James,[],"[{'message': ""Yes, this PR is bigger than necessary. It's intentional; for issues of this nature, I'd rather purge everything related with a wide margin. Better safe than sorry.\n\nThe bug report tells how to trigger that issue; once the dust settles, it will be easy to rerun the reproduction steps and see if it still crashes, and if yes, someone uninvolved can create a new fix, or revert the revert."", 'score': -0.08413189649581909, 'timestamp': '2024-03-29T22:04:03Z', 'file_name': 'pr_95.csv'}]",[]
Joshua Peisach,,[],[],"[{'message': ""Honestly, might be best to revert all commits in the past 3 months or so, or just find an older tagged version that hasn't probably been force pushed. It's possible that the bad actor modified old commit logs and whatnot"", 'score': -0.465685835108161, 'timestamp': '2024-03-29T22:23:16Z', 'file_name': 'pr_95.csv'}]"
,Marco Köpcke,[],"[{'message': 'It was easier to revert the entire commit than only revert parts of it.\n\nThat entire line is removed in a subsequent commit (1efea8d8ec96676850341532970f90ec9db7d964), so the end result is the same.', 'score': -0.07820648141205311, 'timestamp': '2024-03-29T22:59:21Z', 'file_name': 'pr_95.csv'}]",[]
Jia Tan,,[],"[{'message': 'Hi! Thank you for the bug report, but I will close this bug report because it is a documented feature of XZ Utils. 7zip and XZ Utils are almost completely compatible with how they treat .xz and .lzma files, but here is an example of where they differ.\n\nMy quick maths determined this file has the settings pb = 1, lp = 3, lc = 5, which is unsupported by XZ Utils. XZ Utils will only compress or decompress .lzma and .xz files if lp + lc <=4.\n\nThis is is documented in doc/lzma-file-format.txt (~ line 105 as of 2022-07-13) and src/liblzma/api/lzma/lzma12.h (~ line 280 as of version 5.4.1). I was not part of the project when this decision was made, but my understanding is that files with lc + lp > 4 are unlikely to improve compression significantly and will use a lot more memory and computation time when compressing or decompressing. \n\nSince .lzma has been a legacy format since 2009 and .xz does not support these types of settings, we do not plan to change this. Old .lzma files that have been created with these settings can still be decompressed with 7zip and new files should be using the .xz format anyway.', 'score': -0.004402969032526016, 'timestamp': '2023-01-16T14:23:49Z', 'file_name': 'issue_20.csv'}]",[]
,Jia Tan,"[{'message': 'thanks for your detailed explanation!', 'score': 0.911573906429112, 'timestamp': '2023-01-16T14:34:57Z', 'file_name': 'issue_20.csv'}]",[],[]
